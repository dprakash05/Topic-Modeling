{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\seaborn\\rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix , classification_report, accuracy_score, roc_auc_score, plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "import spacy\n",
    "import ast\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 800)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn --user\n",
    "#!pip install pyLDAvis --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bbc-text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"stopwords/extended_stopwords.txt\", \"r\")\n",
    "stop_words.extend([line.strip() for line in file.readlines()])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"stopwords/contractions.txt\", \"r\")\n",
    "contractions = ast.literal_eval(file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3+4+4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"3+4+4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tech' 'business' 'sport' 'entertainment' 'politics']\n"
     ]
    }
   ],
   "source": [
    "print(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.text.values.tolist()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time.  that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite pastimes. with the us leading the trend  programmes and other content will be delivered to viewers via home networks  through cable  satellite  telecoms companies  and broadband service providers to front rooms and portable devices.  one of the most talked-about technologies of ces has been digital and personal video recorders (dvr and pvr). these set-top boxes  like the us s tivo and the uk s sky+ system  allow people to record  store  play  pause and forward wind tv programmes when they want.  essentially  the technology allows for much more personalised tv. they are also being built-in to high-definition tv sets  which are big business in japan and the us  but slower to take off in europe because of the lack of high-definition programming. not only can people forward wind through adverts  they can also forget about abiding by network and channel schedules  putting together their own a-la-carte entertainment. but some us networks and cable and satellite companies are worried about what it means for them in terms of advertising revenues as well as  brand identity  and viewer loyalty to channels. although the us leads in this technology at the moment  it is also a concern that is being raised in europe  particularly with the growing uptake of services like sky+.  what happens here today  we will see in nine months to a years  time in the uk   adam hume  the bbc broadcast s futurologist told the bbc news website. for the likes of the bbc  there are no issues of lost advertising revenue yet. it is a more pressing issue at the moment for commercial uk broadcasters  but brand loyalty is important for everyone.  we will be talking more about content brands rather than network brands   said tim hanlon  from brand communications firm starcom mediavest.  the reality is that with broadband connections  anybody can be the producer of content.  he added:  the challenge now is that it is hard to promote a programme with so much choice.   what this means  said stacey jolna  senior vice president of tv guide tv group  is that the way people find the content they want to watch has to be simplified for tv viewers. it means that networks  in us terms  or channels could take a leaf out of google s book and be the search engine of the future  instead of the scheduler to help people find what they want to watch. this kind of channel model might work for the younger ipod generation which is used to taking control of their gadgets and what they play on them. but it might not suit everyone  the panel recognised. older generations are more comfortable with familiar schedules and channel brands because they know what they are getting. they perhaps do not want so much of the choice put into their hands  mr hanlon suggested.  on the other end  you have the kids just out of diapers who are pushing buttons already - everything is possible and available to them   said mr hanlon.  ultimately  the consumer will tell the market they want.   of the 50 000 new gadgets and technologies being showcased at ces  many of them are about enhancing the tv-watching experience. high-definition tv sets are everywhere and many new models of lcd (liquid crystal display) tvs have been launched with dvr capability built into them  instead of being external boxes. one such example launched at the show is humax s 26-inch lcd tv with an 80-hour tivo dvr and dvd recorder. one of the us s biggest satellite tv companies  directtv  has even launched its own branded dvr at the show with 100-hours of recording capability  instant replay  and a search function. the set can pause and rewind tv for up to 90 hours. and microsoft chief bill gates announced in his pre-show keynote speech a partnership with tivo  called tivotogo  which means people can play recorded programmes on windows pcs and mobile devices. all these reflect the increasing trend of freeing up multimedia so that people can watch what they want  when they want.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tv future in the hands of viewers with home theatre systems plasma '\n",
      " 'high-definition tvs and digital video recorders moving into the living room '\n",
      " 'the way people watch tv will be radically different in five years time. that '\n",
      " 'is according to an expert panel which gathered at the annual consumer '\n",
      " 'electronics show in las vegas to discuss how these new technologies will '\n",
      " 'impact one of our favourite pastimes. with the us leading the trend '\n",
      " 'programmes and other content will be delivered to viewers via home networks '\n",
      " 'through cable satellite telecoms companies and broadband service providers '\n",
      " 'to front rooms and portable devices. one of the most talked-about '\n",
      " 'technologies of ces has been digital and personal video recorders (dvr and '\n",
      " 'pvr). these set-top boxes like the us s tivo and the uk s sky+ system allow '\n",
      " 'people to record store play pause and forward wind tv programmes when they '\n",
      " 'want. essentially the technology allows for much more personalised tv. they '\n",
      " 'are also being built-in to high-definition tv sets which are big business in '\n",
      " 'japan and the us but slower to take off in europe because of the lack of '\n",
      " 'high-definition programming. not only can people forward wind through '\n",
      " 'adverts they can also forget about abiding by network and channel schedules '\n",
      " 'putting together their own a-la-carte entertainment. but some us networks '\n",
      " 'and cable and satellite companies are worried about what it means for them '\n",
      " 'in terms of advertising revenues as well as brand identity and viewer '\n",
      " 'loyalty to channels. although the us leads in this technology at the moment '\n",
      " 'it is also a concern that is being raised in europe particularly with the '\n",
      " 'growing uptake of services like sky+. what happens here today we will see in '\n",
      " 'nine months to a years time in the uk adam hume the bbc broadcast s '\n",
      " 'futurologist told the bbc news website. for the likes of the bbc there are '\n",
      " 'no issues of lost advertising revenue yet. it is a more pressing issue at '\n",
      " 'the moment for commercial uk broadcasters but brand loyalty is important for '\n",
      " 'everyone. we will be talking more about content brands rather than network '\n",
      " 'brands said tim hanlon from brand communications firm starcom mediavest. the '\n",
      " 'reality is that with broadband connections anybody can be the producer of '\n",
      " 'content. he added: the challenge now is that it is hard to promote a '\n",
      " 'programme with so much choice. what this means said stacey jolna senior vice '\n",
      " 'president of tv guide tv group is that the way people find the content they '\n",
      " 'want to watch has to be simplified for tv viewers. it means that networks in '\n",
      " 'us terms or channels could take a leaf out of google s book and be the '\n",
      " 'search engine of the future instead of the scheduler to help people find '\n",
      " 'what they want to watch. this kind of channel model might work for the '\n",
      " 'younger ipod generation which is used to taking control of their gadgets and '\n",
      " 'what they play on them. but it might not suit everyone the panel recognised. '\n",
      " 'older generations are more comfortable with familiar schedules and channel '\n",
      " 'brands because they know what they are getting. they perhaps do not want so '\n",
      " 'much of the choice put into their hands mr hanlon suggested. on the other '\n",
      " 'end you have the kids just out of diapers who are pushing buttons already - '\n",
      " 'everything is possible and available to them said mr hanlon. ultimately the '\n",
      " 'consumer will tell the market they want. of the 50 000 new gadgets and '\n",
      " 'technologies being showcased at ces many of them are about enhancing the '\n",
      " 'tv-watching experience. high-definition tv sets are everywhere and many new '\n",
      " 'models of lcd (liquid crystal display) tvs have been launched with dvr '\n",
      " 'capability built into them instead of being external boxes. one such example '\n",
      " 'launched at the show is humax s 26-inch lcd tv with an 80-hour tivo dvr and '\n",
      " 'dvd recorder. one of the us s biggest satellite tv companies directtv has '\n",
      " 'even launched its own branded dvr at the show with 100-hours of recording '\n",
      " 'capability instant replay and a search function. the set can pause and '\n",
      " 'rewind tv for up to 90 hours. and microsoft chief bill gates announced in '\n",
      " 'his pre-show keynote speech a partnership with tivo called tivotogo which '\n",
      " 'means people can play recorded programmes on windows pcs and mobile devices. '\n",
      " 'all these reflect the increasing trend of freeing up multimedia so that '\n",
      " 'people can watch what they want when they want.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\",\" \", sent) for sent in data]\n",
    "\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high', 'definition', 'tvs', 'and', 'digital', 'video', 'recorders', 'moving', 'into', 'the', 'living', 'room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer', 'electronics', 'show', 'in', 'las', 'vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service', 'providers', 'to', 'front', 'rooms', 'and', 'portable', 'devices', 'one', 'of', 'the', 'most', 'talked', 'about', 'technologies', 'of', 'ces', 'has', 'been', 'digital', 'and', 'personal', 'video', 'recorders', 'dvr', 'and', 'pvr', 'these', 'set', 'top', 'boxes', 'like', 'the', 'us', 'tivo', 'and', 'the', 'uk', 'sky', 'system', 'allow', 'people', 'to', 'record', 'store', 'play', 'pause', 'and', 'forward', 'wind', 'tv', 'programmes', 'when', 'they', 'want', 'essentially', 'the', 'technology', 'allows', 'for', 'much', 'more', 'personalised', 'tv', 'they', 'are', 'also', 'being', 'built', 'in', 'to', 'high', 'definition', 'tv', 'sets', 'which', 'are', 'big', 'business', 'in', 'japan', 'and', 'the', 'us', 'but', 'slower', 'to', 'take', 'off', 'in', 'europe', 'because', 'of', 'the', 'lack', 'of', 'high', 'definition', 'programming', 'not', 'only', 'can', 'people', 'forward', 'wind', 'through', 'adverts', 'they', 'can', 'also', 'forget', 'about', 'abiding', 'by', 'network', 'and', 'channel', 'schedules', 'putting', 'together', 'their', 'own', 'la', 'carte', 'entertainment', 'but', 'some', 'us', 'networks', 'and', 'cable', 'and', 'satellite', 'companies', 'are', 'worried', 'about', 'what', 'it', 'means', 'for', 'them', 'in', 'terms', 'of', 'advertising', 'revenues', 'as', 'well', 'as', 'brand', 'identity', 'and', 'viewer', 'loyalty', 'to', 'channels', 'although', 'the', 'us', 'leads', 'in', 'this', 'technology', 'at', 'the', 'moment', 'it', 'is', 'also', 'concern', 'that', 'is', 'being', 'raised', 'in', 'europe', 'particularly', 'with', 'the', 'growing', 'uptake', 'of', 'services', 'like', 'sky', 'what', 'happens', 'here', 'today', 'we', 'will', 'see', 'in', 'nine', 'months', 'to', 'years', 'time', 'in', 'the', 'uk', 'adam', 'hume', 'the', 'bbc', 'broadcast', 'futurologist', 'told', 'the', 'bbc', 'news', 'website', 'for', 'the', 'likes', 'of', 'the', 'bbc', 'there', 'are', 'no', 'issues', 'of', 'lost', 'advertising', 'revenue', 'yet', 'it', 'is', 'more', 'pressing', 'issue', 'at', 'the', 'moment', 'for', 'commercial', 'uk', 'broadcasters', 'but', 'brand', 'loyalty', 'is', 'important', 'for', 'everyone', 'we', 'will', 'be', 'talking', 'more', 'about', 'content', 'brands', 'rather', 'than', 'network', 'brands', 'said', 'tim', 'hanlon', 'from', 'brand', 'communications', 'firm', 'starcom', 'mediavest', 'the', 'reality', 'is', 'that', 'with', 'broadband', 'connections', 'anybody', 'can', 'be', 'the', 'producer', 'of', 'content', 'he', 'added', 'the', 'challenge', 'now', 'is', 'that', 'it', 'is', 'hard', 'to', 'promote', 'programme', 'with', 'so', 'much', 'choice', 'what', 'this', 'means', 'said', 'stacey', 'jolna', 'senior', 'vice', 'president', 'of', 'tv', 'guide', 'tv', 'group', 'is', 'that', 'the', 'way', 'people', 'find', 'the', 'content', 'they', 'want', 'to', 'watch', 'has', 'to', 'be', 'simplified', 'for', 'tv', 'viewers', 'it', 'means', 'that', 'networks', 'in', 'us', 'terms', 'or', 'channels', 'could', 'take', 'leaf', 'out', 'of', 'google', 'book', 'and', 'be', 'the', 'search', 'engine', 'of', 'the', 'future', 'instead', 'of', 'the', 'scheduler', 'to', 'help', 'people', 'find', 'what', 'they', 'want', 'to', 'watch', 'this', 'kind', 'of', 'channel', 'model', 'might', 'work', 'for', 'the', 'younger', 'ipod', 'generation', 'which', 'is', 'used', 'to', 'taking', 'control', 'of', 'their', 'gadgets', 'and', 'what', 'they', 'play', 'on', 'them', 'but', 'it', 'might', 'not', 'suit', 'everyone', 'the', 'panel', 'recognised', 'older', 'generations', 'are', 'more', 'comfortable', 'with', 'familiar', 'schedules', 'and', 'channel', 'brands', 'because', 'they', 'know', 'what', 'they', 'are', 'getting', 'they', 'perhaps', 'do', 'not', 'want', 'so', 'much', 'of', 'the', 'choice', 'put', 'into', 'their', 'hands', 'mr', 'hanlon', 'suggested', 'on', 'the', 'other', 'end', 'you', 'have', 'the', 'kids', 'just', 'out', 'of', 'diapers', 'who', 'are', 'pushing', 'buttons', 'already', 'everything', 'is', 'possible', 'and', 'available', 'to', 'them', 'said', 'mr', 'hanlon', 'ultimately', 'the', 'consumer', 'will', 'tell', 'the', 'market', 'they', 'want', 'of', 'the', 'new', 'gadgets', 'and', 'technologies', 'being', 'showcased', 'at', 'ces', 'many', 'of', 'them', 'are', 'about', 'enhancing', 'the', 'tv', 'watching', 'experience', 'high', 'definition', 'tv', 'sets', 'are', 'everywhere', 'and', 'many', 'new', 'models', 'of', 'lcd', 'liquid', 'crystal', 'display', 'tvs', 'have', 'been', 'launched', 'with', 'dvr', 'capability', 'built', 'into', 'them', 'instead', 'of', 'being', 'external', 'boxes', 'one', 'such', 'example', 'launched', 'at', 'the', 'show', 'is', 'humax', 'inch', 'lcd', 'tv', 'with', 'an', 'hour', 'tivo', 'dvr', 'and', 'dvd', 'recorder', 'one', 'of', 'the', 'us', 'biggest', 'satellite', 'tv', 'companies', 'directtv', 'has', 'even', 'launched', 'its', 'own', 'branded', 'dvr', 'at', 'the', 'show', 'with', 'hours', 'of', 'recording', 'capability', 'instant', 'replay', 'and', 'search', 'function', 'the', 'set', 'can', 'pause', 'and', 'rewind', 'tv', 'for', 'up', 'to', 'hours', 'and', 'microsoft', 'chief', 'bill', 'gates', 'announced', 'in', 'his', 'pre', 'show', 'keynote', 'speech', 'partnership', 'with', 'tivo', 'called', 'tivotogo', 'which', 'means', 'people', 'can', 'play', 'recorded', 'programmes', 'on', 'windows', 'pcs', 'and', 'mobile', 'devices', 'all', 'these', 'reflect', 'the', 'increasing', 'trend', 'of', 'freeing', 'up', 'multimedia', 'so', 'that', 'people', 'can', 'watch', 'what', 'they', 'want', 'when', 'they', 'want']\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence).encode('utf-8'), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)# higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high_definition', 'tvs', 'and', 'digital', 'video_recorders', 'moving', 'into', 'the', 'living_room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer_electronics', 'show', 'in', 'las_vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service_providers', 'to', 'front', 'rooms', 'and', 'portable_devices', 'one', 'of', 'the', 'most', 'talked', 'about', 'technologies', 'of', 'ces', 'has', 'been', 'digital', 'and', 'personal', 'video_recorders', 'dvr', 'and', 'pvr', 'these', 'set', 'top_boxes', 'like', 'the', 'us', 'tivo', 'and', 'the', 'uk', 'sky', 'system', 'allow', 'people', 'to', 'record', 'store', 'play', 'pause', 'and', 'forward', 'wind', 'tv_programmes', 'when', 'they', 'want', 'essentially', 'the', 'technology', 'allows', 'for', 'much', 'more', 'personalised', 'tv', 'they', 'are', 'also', 'being', 'built', 'in', 'to', 'high_definition', 'tv', 'sets', 'which', 'are', 'big', 'business', 'in', 'japan', 'and', 'the', 'us', 'but', 'slower', 'to', 'take', 'off', 'in', 'europe', 'because', 'of', 'the', 'lack', 'of', 'high_definition', 'programming', 'not', 'only', 'can', 'people', 'forward', 'wind', 'through', 'adverts', 'they', 'can', 'also', 'forget', 'about', 'abiding', 'by', 'network', 'and', 'channel', 'schedules', 'putting', 'together', 'their', 'own', 'la', 'carte', 'entertainment', 'but', 'some', 'us', 'networks', 'and', 'cable', 'and', 'satellite', 'companies', 'are', 'worried', 'about', 'what', 'it', 'means', 'for', 'them', 'in', 'terms', 'of', 'advertising', 'revenues', 'as', 'well', 'as', 'brand', 'identity', 'and', 'viewer', 'loyalty', 'to', 'channels', 'although', 'the', 'us', 'leads', 'in', 'this', 'technology', 'at', 'the', 'moment', 'it', 'is', 'also', 'concern', 'that', 'is', 'being', 'raised', 'in', 'europe', 'particularly', 'with', 'the', 'growing', 'uptake', 'of', 'services', 'like', 'sky', 'what', 'happens', 'here', 'today', 'we', 'will', 'see', 'in', 'nine', 'months', 'to', 'years', 'time', 'in', 'the', 'uk', 'adam', 'hume', 'the', 'bbc', 'broadcast', 'futurologist', 'told', 'the', 'bbc_news', 'website', 'for', 'the', 'likes', 'of', 'the', 'bbc', 'there', 'are', 'no', 'issues', 'of', 'lost', 'advertising', 'revenue', 'yet', 'it', 'is', 'more', 'pressing', 'issue', 'at', 'the', 'moment', 'for', 'commercial', 'uk', 'broadcasters', 'but', 'brand', 'loyalty', 'is', 'important', 'for', 'everyone', 'we', 'will', 'be', 'talking', 'more', 'about', 'content', 'brands', 'rather_than', 'network', 'brands', 'said', 'tim', 'hanlon', 'from', 'brand', 'communications', 'firm', 'starcom', 'mediavest', 'the', 'reality', 'is', 'that', 'with', 'broadband', 'connections', 'anybody', 'can', 'be', 'the', 'producer', 'of', 'content', 'he', 'added', 'the', 'challenge', 'now', 'is', 'that', 'it', 'is', 'hard', 'to', 'promote', 'programme', 'with', 'so', 'much', 'choice', 'what', 'this', 'means', 'said', 'stacey', 'jolna', 'senior_vice', 'president', 'of', 'tv', 'guide', 'tv', 'group', 'is', 'that', 'the', 'way', 'people', 'find', 'the', 'content', 'they', 'want', 'to', 'watch', 'has', 'to', 'be', 'simplified', 'for', 'tv', 'viewers', 'it', 'means', 'that', 'networks', 'in', 'us', 'terms', 'or', 'channels', 'could', 'take', 'leaf', 'out', 'of', 'google', 'book', 'and', 'be', 'the', 'search_engine', 'of', 'the', 'future', 'instead', 'of', 'the', 'scheduler', 'to', 'help', 'people', 'find', 'what', 'they', 'want', 'to', 'watch', 'this', 'kind', 'of', 'channel', 'model', 'might', 'work', 'for', 'the', 'younger', 'ipod', 'generation', 'which', 'is', 'used', 'to', 'taking', 'control', 'of', 'their', 'gadgets', 'and', 'what', 'they', 'play', 'on', 'them', 'but', 'it', 'might', 'not', 'suit', 'everyone', 'the', 'panel', 'recognised', 'older', 'generations', 'are', 'more', 'comfortable', 'with', 'familiar', 'schedules', 'and', 'channel', 'brands', 'because', 'they', 'know', 'what', 'they', 'are', 'getting', 'they', 'perhaps', 'do', 'not', 'want', 'so', 'much', 'of', 'the', 'choice', 'put', 'into', 'their', 'hands', 'mr', 'hanlon', 'suggested', 'on', 'the', 'other', 'end', 'you', 'have', 'the', 'kids', 'just', 'out', 'of', 'diapers', 'who', 'are', 'pushing', 'buttons', 'already', 'everything', 'is', 'possible', 'and', 'available', 'to', 'them', 'said', 'mr', 'hanlon', 'ultimately', 'the', 'consumer', 'will', 'tell', 'the', 'market', 'they', 'want', 'of', 'the', 'new', 'gadgets', 'and', 'technologies', 'being', 'showcased', 'at', 'ces', 'many', 'of', 'them', 'are', 'about', 'enhancing', 'the', 'tv', 'watching', 'experience', 'high_definition', 'tv', 'sets', 'are', 'everywhere', 'and', 'many', 'new', 'models', 'of', 'lcd', 'liquid', 'crystal', 'display', 'tvs', 'have', 'been', 'launched', 'with', 'dvr', 'capability', 'built', 'into', 'them', 'instead', 'of', 'being', 'external', 'boxes', 'one', 'such', 'example', 'launched', 'at', 'the', 'show', 'is', 'humax', 'inch', 'lcd', 'tv', 'with', 'an', 'hour', 'tivo', 'dvr', 'and', 'dvd', 'recorder', 'one', 'of', 'the', 'us', 'biggest', 'satellite', 'tv', 'companies', 'directtv', 'has', 'even', 'launched', 'its', 'own', 'branded', 'dvr', 'at', 'the', 'show', 'with', 'hours', 'of', 'recording', 'capability', 'instant', 'replay', 'and', 'search', 'function', 'the', 'set', 'can', 'pause', 'and', 'rewind', 'tv', 'for', 'up', 'to', 'hours', 'and', 'microsoft', 'chief', 'bill_gates', 'announced', 'in', 'his', 'pre', 'show', 'keynote_speech', 'partnership', 'with', 'tivo', 'called', 'tivotogo', 'which', 'means', 'people', 'can', 'play', 'recorded', 'programmes', 'on', 'windows', 'pcs', 'and', 'mobile', 'devices', 'all', 'these', 'reflect', 'the', 'increasing', 'trend', 'of', 'freeing', 'up', 'multimedia', 'so', 'that', 'people', 'can', 'watch', 'what', 'they', 'want', 'when', 'they', 'want']\n"
     ]
    }
   ],
   "source": [
    "# See bigram example\n",
    "print(bigram_mod[data_words[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "nlp = spacy.load(' , disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "print(len(data_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpusa\n",
    "texts = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 7), (10, 2), (11, 2), (12, 1), (13, 1), (14, 2), (15, 1), (16, 2), (17, 2), (18, 1), (19, 4), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 1), (30, 4), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 3), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 2), (54, 1), (55, 1), (56, 1), (57, 2), (58, 2), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 1), (67, 4), (68, 3), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 2), (76, 1), (77, 1), (78, 1), (79, 3), (80, 2), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 2), (90, 2), (91, 1), (92, 1), (93, 1), (94, 5), (95, 1), (96, 2), (97, 1), (98, 1), (99, 2), (100, 7), (101, 1), (102, 1), (103, 1), (104, 3), (105, 1), (106, 1), (107, 1), (108, 3), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 2), (124, 1), (125, 1), (126, 3), (127, 2), (128, 1), (129, 1), (130, 1), (131, 1), (132, 4), (133, 1), (134, 1), (135, 2), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 2), (142, 2), (143, 5), (144, 1), (145, 2), (146, 1), (147, 2), (148, 1), (149, 1), (150, 2), (151, 13), (152, 1), (153, 1), (154, 1), (155, 4), (156, 4), (157, 1), (158, 2), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1)]\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abide'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('abide', 1),\n",
       "  ('advert', 1),\n",
       "  ('advertising', 2),\n",
       "  ('announce', 1),\n",
       "  ('annual', 1),\n",
       "  ('big', 2),\n",
       "  ('bill_gate', 1),\n",
       "  ('book', 1),\n",
       "  ('box', 1),\n",
       "  ('brand', 7),\n",
       "  ('broadband', 2),\n",
       "  ('build', 2),\n",
       "  ('business', 1),\n",
       "  ('button', 1),\n",
       "  ('cable', 2),\n",
       "  ('call', 1),\n",
       "  ('capability', 2),\n",
       "  ('ce', 2),\n",
       "  ('challenge', 1),\n",
       "  ('channel', 4),\n",
       "  ('chief', 1),\n",
       "  ('choice', 2),\n",
       "  ('comfortable', 1),\n",
       "  ('commercial', 1),\n",
       "  ('communication', 1),\n",
       "  ('company', 3),\n",
       "  ('concern', 1),\n",
       "  ('connection', 1),\n",
       "  ('consumer', 1),\n",
       "  ('consumer_electronic', 1),\n",
       "  ('content', 4),\n",
       "  ('control', 1),\n",
       "  ('crystal', 1),\n",
       "  ('deliver', 1),\n",
       "  ('device', 1),\n",
       "  ('diaper', 1),\n",
       "  ('digital', 2),\n",
       "  ('directtv', 1),\n",
       "  ('discuss', 1),\n",
       "  ('display', 1),\n",
       "  ('dvd', 1),\n",
       "  ('dvr', 3),\n",
       "  ('enhance', 1),\n",
       "  ('entertainment', 1),\n",
       "  ('essentially', 1),\n",
       "  ('experience', 1),\n",
       "  ('expert', 1),\n",
       "  ('external', 1),\n",
       "  ('familiar', 1),\n",
       "  ('favourite', 1),\n",
       "  ('find', 2),\n",
       "  ('firm', 1),\n",
       "  ('forget', 1),\n",
       "  ('forward', 2),\n",
       "  ('free', 1),\n",
       "  ('front', 1),\n",
       "  ('function', 1),\n",
       "  ('future', 2),\n",
       "  ('gadget', 2),\n",
       "  ('gather', 1),\n",
       "  ('generation', 2),\n",
       "  ('group', 1),\n",
       "  ('grow', 1),\n",
       "  ('guide', 1),\n",
       "  ('hand', 2),\n",
       "  ('hanlon', 1),\n",
       "  ('hard', 1),\n",
       "  ('high_definition', 4),\n",
       "  ('hour', 3),\n",
       "  ('hume', 1),\n",
       "  ('identity', 1),\n",
       "  ('impact', 1),\n",
       "  ('increase', 1),\n",
       "  ('instant', 1),\n",
       "  ('ipod', 1),\n",
       "  ('issue', 2),\n",
       "  ('kid', 1),\n",
       "  ('lack', 1),\n",
       "  ('las_vega', 1),\n",
       "  ('launch', 3),\n",
       "  ('lead', 2),\n",
       "  ('leaf', 1),\n",
       "  ('like', 1),\n",
       "  ('living_room', 1),\n",
       "  ('lose', 1),\n",
       "  ('loyalty', 2),\n",
       "  ('market', 1),\n",
       "  ('mediav', 1),\n",
       "  ('mobile', 1),\n",
       "  ('model', 2),\n",
       "  ('moment', 2),\n",
       "  ('month', 1),\n",
       "  ('move', 1),\n",
       "  ('multimedia', 1),\n",
       "  ('network', 5),\n",
       "  ('old', 1),\n",
       "  ('panel', 2),\n",
       "  ('partnership', 1),\n",
       "  ('pastime', 1),\n",
       "  ('pause', 2),\n",
       "  ('people', 7),\n",
       "  ('personal', 1),\n",
       "  ('personalise', 1),\n",
       "  ('plasma', 1),\n",
       "  ('play', 3),\n",
       "  ('portable_device', 1),\n",
       "  ('press', 1),\n",
       "  ('producer', 1),\n",
       "  ('programme', 3),\n",
       "  ('programming', 1),\n",
       "  ('promote', 1),\n",
       "  ('push', 1),\n",
       "  ('put', 1),\n",
       "  ('pvr', 1),\n",
       "  ('radically', 1),\n",
       "  ('raise', 1),\n",
       "  ('reality', 1),\n",
       "  ('recognise', 1),\n",
       "  ('record', 2),\n",
       "  ('recorder', 1),\n",
       "  ('recording', 1),\n",
       "  ('reflect', 1),\n",
       "  ('replay', 1),\n",
       "  ('revenue', 2),\n",
       "  ('rewind', 1),\n",
       "  ('room', 1),\n",
       "  ('satellite', 3),\n",
       "  ('schedule', 2),\n",
       "  ('scheduler', 1),\n",
       "  ('search', 1),\n",
       "  ('service', 1),\n",
       "  ('service_provider', 1),\n",
       "  ('set', 4),\n",
       "  ('showcase', 1),\n",
       "  ('simplify', 1),\n",
       "  ('sky', 2),\n",
       "  ('slow', 1),\n",
       "  ('starcom', 1),\n",
       "  ('store', 1),\n",
       "  ('suggest', 1),\n",
       "  ('suit', 1),\n",
       "  ('system', 2),\n",
       "  ('talk', 2),\n",
       "  ('technology', 5),\n",
       "  ('telecom', 1),\n",
       "  ('term', 2),\n",
       "  ('theatre', 1),\n",
       "  ('time', 2),\n",
       "  ('tivo', 1),\n",
       "  ('top_boxe', 1),\n",
       "  ('trend', 2),\n",
       "  ('tv', 13),\n",
       "  ('ultimately', 1),\n",
       "  ('uptake', 1),\n",
       "  ('video_recorder', 1),\n",
       "  ('viewer', 4),\n",
       "  ('watch', 4),\n",
       "  ('watching', 1),\n",
       "  ('wind', 2),\n",
       "  ('window', 1),\n",
       "  ('work', 1),\n",
       "  ('worry', 1),\n",
       "  ('year', 2),\n",
       "  ('young', 1)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(round(coherencemodel.get_coherence(),3))\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [03:32<00:00, 35.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run\n",
    "model_list, coherence_values = tune_model(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=8, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=8; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.322\n",
      "Num Topics = 3  has Coherence Value of 0.412\n",
      "Num Topics = 4  has Coherence Value of 0.46\n",
      "Num Topics = 5  has Coherence Value of 0.532\n",
      "Num Topics = 6  has Coherence Value of 0.499\n",
      "Num Topics = 7  has Coherence Value of 0.529\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.017*\"people\" + 0.010*\"technology\" + 0.008*\"mobile\" + 0.008*\"computer\" + '\n",
      "  '0.008*\"net\" + 0.008*\"network\" + 0.007*\"service\" + 0.007*\"user\" + '\n",
      "  '0.007*\"site\" + 0.007*\"phone\"'),\n",
      " (1,\n",
      "  '0.023*\"film\" + 0.013*\"year\" + 0.011*\"award\" + 0.009*\"music\" + '\n",
      "  '0.009*\"include\" + 0.008*\"star\" + 0.008*\"top\" + 0.007*\"number\" + '\n",
      "  '0.006*\"dance\" + 0.006*\"album\"'),\n",
      " (2,\n",
      "  '0.018*\"year\" + 0.013*\"sale\" + 0.013*\"rise\" + 0.012*\"company\" + 0.010*\"firm\" '\n",
      "  '+ 0.008*\"expect\" + 0.007*\"market\" + 0.007*\"fall\" + 0.007*\"price\" + '\n",
      "  '0.007*\"share\"'),\n",
      " (3,\n",
      "  '0.010*\"government\" + 0.010*\"people\" + 0.008*\"labour\" + 0.007*\"party\" + '\n",
      "  '0.007*\"plan\" + 0.005*\"tell\" + 0.005*\"issue\" + 0.005*\"country\" + '\n",
      "  '0.005*\"claim\" + 0.005*\"election\"'),\n",
      " (4,\n",
      "  '0.020*\"game\" + 0.015*\"play\" + 0.012*\"player\" + 0.011*\"time\" + 0.011*\"win\" + '\n",
      "  '0.009*\"year\" + 0.007*\"team\" + 0.007*\"club\" + 0.007*\"match\" + 0.006*\"good\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0::['people', 'technology', 'mobile', 'computer', 'net', 'network', 'service', 'user', 'site', 'phone', 'music', 'software', 'tv', 'digital', 'firm', 'attack', 'information', 'work', 'online', 'datum']\n",
      "1::['film', 'year', 'award', 'music', 'include', 'star', 'top', 'number', 'dance', 'album', 'director', 'british', 'song', 'prisoner', 'chart', 'play', 'release', 'tv', 'die', 'band']\n",
      "2::['year', 'sale', 'rise', 'company', 'firm', 'expect', 'market', 'fall', 'price', 'share', 'report', 'figure', 'growth', 'high', 'cost', 'bank', 'economy', 'business', 'car', 'big']\n",
      "3::['government', 'people', 'labour', 'party', 'plan', 'tell', 'issue', 'country', 'claim', 'election', 'public', 'law', 'work', 'case', 'call', 'tory', 'rule', 'decision', 'year', 'policy']\n",
      "4::['game', 'play', 'player', 'time', 'win', 'year', 'team', 'club', 'match', 'good', 'side', 'set', 'goal', 'half', 'sport', 'lose', 'start', 'minute', 'week', 'manager']\n",
      "\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "x = optimal_model.show_topics(num_topics=5, num_words=20, formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "# Below Code Prints Topics and Words\n",
    "for topic, words in topics_words:\n",
    "    print(str(topic) + \"::\" + str(words))\n",
    "print()\n",
    "\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12020/662046927.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12020/662046927.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_No</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>people, technology, mobile, computer, net, net...</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>tv future hand viewer theatre system plasma hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>year, sale, rise, company, firm, expect, marke...</td>\n",
       "      <td>worldcom boss left books alone former worldcom...</td>\n",
       "      <td>boss leave book ebber accuse oversee fraud acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>game, play, player, time, win, year, team, clu...</td>\n",
       "      <td>tigers wary of farrell gamble leicester say th...</td>\n",
       "      <td>tiger wary gamble leicester rush make bid deci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>game, play, player, time, win, year, team, clu...</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>yeade face newcastle premiership side trip rym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>film, year, award, music, include, star, top, ...</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>raid box_office crime caper sequel star george...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>government, people, labour, party, plan, tell,...</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "      <td>hit mongrel jibe claim act attack mongrel labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>government, people, labour, party, plan, tell,...</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "      <td>prepare poll election day parliament return le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>game, play, player, time, win, year, team, clu...</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "      <td>hope end dubai seed slump straight set defeat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>game, play, player, time, win, year, team, clu...</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "      <td>return play injure bicep full contact training...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>film, year, award, music, include, star, top, ...</td>\n",
       "      <td>last star wars not for children the sixth and ...</td>\n",
       "      <td>star_war child sixth final star_war movie suit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_No  Topic_Perc_Contrib  \\\n",
       "0         0              0.8349   \n",
       "1         2              0.4834   \n",
       "2         4              0.7149   \n",
       "3         4              0.9513   \n",
       "4         1              0.9510   \n",
       "5         3              0.8490   \n",
       "6         3              0.8677   \n",
       "7         4              0.7420   \n",
       "8         4              0.8565   \n",
       "9         1              0.7213   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  people, technology, mobile, computer, net, net...   \n",
       "1  year, sale, rise, company, firm, expect, marke...   \n",
       "2  game, play, player, time, win, year, team, clu...   \n",
       "3  game, play, player, time, win, year, team, clu...   \n",
       "4  film, year, award, music, include, star, top, ...   \n",
       "5  government, people, labour, party, plan, tell,...   \n",
       "6  government, people, labour, party, plan, tell,...   \n",
       "7  game, play, player, time, win, year, team, clu...   \n",
       "8  game, play, player, time, win, year, team, clu...   \n",
       "9  film, year, award, music, include, star, top, ...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  tv future in the hands of viewers with home th...   \n",
       "1  worldcom boss left books alone former worldcom...   \n",
       "2  tigers wary of farrell gamble leicester say th...   \n",
       "3  yeading face newcastle in fa cup premiership s...   \n",
       "4  ocean s twelve raids box office ocean s twelve...   \n",
       "5  howard hits back at mongrel jibe michael howar...   \n",
       "6  blair prepares to name poll date tony blair is...   \n",
       "7  henman hopes ended in dubai third seed tim hen...   \n",
       "8  wilkinson fit to face edinburgh england captai...   \n",
       "9  last star wars not for children the sixth and ...   \n",
       "\n",
       "                                          Clean_Text  \n",
       "0  tv future hand viewer theatre system plasma hi...  \n",
       "1  boss leave book ebber accuse oversee fraud acc...  \n",
       "2  tiger wary gamble leicester rush make bid deci...  \n",
       "3  yeade face newcastle premiership side trip rym...  \n",
       "4  raid box_office crime caper sequel star george...  \n",
       "5  hit mongrel jibe claim act attack mongrel labo...  \n",
       "6  prepare poll election day parliament return le...  \n",
       "7  hope end dubai seed slump straight set defeat ...  \n",
       "8  return play injure bicep full contact training...  \n",
       "9  star_war child sixth final star_war movie suit...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        \n",
    "        row = sorted(row[0], key=lambda x: x[1], reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Topic_No', 'Topic_Perc_Contrib', 'Topic_Keywords', 'Text']\n",
    "\n",
    "final_df = df_dominant_topic.drop(\"Document_No\", axis=1)\n",
    "\n",
    "# add clean text Show\n",
    "clean_text = [ \" \".join(i) for i in texts]\n",
    "final_df[\"Clean_Text\"] = clean_text\n",
    "\n",
    "# show\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    560\n",
       "4    490\n",
       "2    446\n",
       "1    379\n",
       "0    350\n",
       "Name: Topic_No, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"Topic_No\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Topic_No', 'Topic_Perc_Contrib', 'Topic_Keywords', 'Text',\n",
       "       'Clean_Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using TFIDF vectorizer\n",
    "\n",
    "# Vectorize training and testing data. Here we would pass TfidfVectorizer() to vec \n",
    "def Vectorize(vec, X_train, X_test):    \n",
    "    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    \n",
    "    \n",
    "    return X_train_vec, X_test_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple classifiers and grid search for prediction\n",
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "## Preparing to make a pipeline \n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(), \n",
    "    'Decision Tree': DecisionTreeClassifier(),  \n",
    "#     'Perceptron': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()   ## This model would take a little longer to run \n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n",
    "    'Decision Tree': { 'min_samples_split': [1, 2, 5] }, \n",
    "#     'Perceptron': { 'alpha': [0.0001, 0.001], 'activation': ['tanh', 'relu'] },\n",
    "    'Gradient Boosting': { 'learning_rate': [0.05, 0.1], 'min_samples_split': [2, 5] }\n",
    "}\n",
    "\n",
    "\n",
    "# Encode label categories to numbers\n",
    "enc = LabelEncoder()\n",
    "final_df['Topic_No'] = enc.fit_transform(final_df['Topic_No'])\n",
    "labels = list(enc.classes_)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete.\n",
      "\n",
      "Naive Bayes : {'alpha': 0.5, 'fit_prior': False}\n",
      "Accuracy: 0.933 \tPrecision: 0.941 \tRecall: 0.929 \t\tF1: 0.932\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree : {'min_samples_split': 2}\n",
      "Accuracy: 0.789 \tPrecision: 0.796 \tRecall: 0.784 \t\tF1: 0.788\n",
      "\n",
      "Gradient Boosting : {'learning_rate': 0.1, 'min_samples_split': 5}\n",
      "Accuracy: 0.928 \tPrecision: 0.928 \tRecall: 0.929 \t\tF1: 0.928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df['Text'], final_df['Topic_No'], test_size=0.2, shuffle=True)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
    "\n",
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)\n",
    "## ML_modeling method also prints performance scores for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df['Text'], final_df['Topic_No'], test_size=0.2, shuffle=True)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
    "\n",
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training and testing data. Here we would pass TfidfVectorizer() to vec \n",
    "def Vectorize(vec, X_train, X_test):    \n",
    "    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    with open('Vectorizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(vec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    \n",
    "    \n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "def build_model(models, params, X_train, X_test, y_train, y_test):\n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    # dump model\n",
    "    with open('model.pickle', 'wb') as handle:\n",
    "        pickle.dump(gs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Model saved..\")\n",
    "    \n",
    "    return gs\n",
    "\n",
    "def clean_input(data):\n",
    "#     data = re.sub(r\"\\b\" + key + r\"\\b\", value, data.lower())\n",
    "    data = re.sub(\"\\s+\", \" \", str(data))\n",
    "    data = re.sub(\"\\S*@\\S*\\s?\", \"\", str(data))\n",
    "    data = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", str(data))\n",
    "    data = re.sub(\"(\\\\d|\\\\W)+\", \" \", str(data))\n",
    "    data = re.sub(\"'\", \"\", data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df['Clean_Text'], final_df['Topic_No'], test_size=0.2, shuffle=True)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] } \n",
    "}\n",
    "\n",
    "model = build_model(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Computer technology is leading to more accurate sizing and rating methods for process equipment. Heat exchangers are designed with high-precision prediction methods and complex numerical techniques to account for the local flow and temperature conditions. Fouling mitigation is just changing from an art to a science-based technology. The real benefits of sophisticated design codes will not be achieved without reliable fouling prediction methods and mitigation techniques that can be incorporated into the design phase. Recent developments in the computer technology provide an opportunity to productively use fouling information that is scattered in the literature, industry log books, and in reports. A long-term goal for the industry is to develop a knowledge-based system for designing and operating heat exchangers with a minimum impact of water fouling. The major challenges to develop the knowledge-based system are as follows:\n",
    "Compilation and organization of the fouling data\n",
    "Easy access by both research organizations and industry\n",
    "Development of a logic system for interpreting the fouling data\n",
    "Industrial acceptance of such knowledge-based systems\n",
    "The fouling data and analyses reported in the literature are often inadequately utilized. To effectively utilize these data, compilation and organization of fouling information are major tasks and challenges for research organizations and industries. This task is more important for the fouling-mitigation technology as compared to other engineering areas. It is hard to imagine that there could be a single correlation with a given set of parameters that can be used to predict the rate of fouling or determine the threshold fouling conditions. One has to rely on the best possible approach to mitigate fouling for a given set of conditions. In the absence of such information, either mitigation methods are overutilized, with high chemical costs, or underutilized, with high maintenance and production costs. Perrakis et al. [54] introduced an approach for compiling the fouling data in the literature. A major cooperative effort is required to carry out such a major challenge for compiling and organizing data. The fouling data and analyses must be accompanied with physical and chemical parameters without which the data have little value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model file\n",
    "with open('model.pickle', 'rb') as handle:\n",
    "    NB_model = pickle.load(handle)\n",
    "    \n",
    "# load vectorizer file\n",
    "with open('Vectorizer.pickle', 'rb') as handle:\n",
    "    vect = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat =  vect.transform([clean_input(input_text)]).toarray()\n",
    "pred = NB_model.predict(feat)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imarticus",
   "language": "python",
   "name": "imarticus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
